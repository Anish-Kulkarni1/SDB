{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89db1824",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "region_name = \"Lakshadweep\"\n",
    "models_dir = None\n",
    "output_dir = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b98640",
   "metadata": {},
   "source": [
    "# Final Visual Showcase for Bathymetry Analysis\n",
    "\n",
    "This notebook creates comprehensive visualizations for the completed bathymetry analysis pipeline.\n",
    "\n",
    "Generated visualizations:\n",
    "1. ğŸ“Š Model Performance Comparison\n",
    "2. ğŸŒˆ Synthetic Depth Distribution\n",
    "3. ğŸ¯ Feature Importance Analysis  \n",
    "4. ğŸ“ˆ Training Metrics Dashboard\n",
    "5. ğŸŒ Interactive Results Summary\n",
    "\n",
    "## Prerequisites\n",
    "- Completed model training (03_model_training.ipynb)\n",
    "- Model files saved in models directory\n",
    "- Performance metrics available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f1f500",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import logging\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Add project root to path\n",
    "project_dir = Path().absolute().parent\n",
    "if project_dir.name != 'sdb_project':\n",
    "    project_dir = project_dir / 'sdb_project'\n",
    "sys.path.append(str(project_dir))\n",
    "\n",
    "# Configure matplotlib for better plots\n",
    "plt.rcParams['figure.figsize'] = [12, 8]\n",
    "plt.rcParams['figure.dpi'] = 150\n",
    "plt.style.use('default')  # Use default style to avoid seaborn issues\n",
    "\n",
    "print(\"âœ… Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6b647e",
   "metadata": {},
   "source": [
    "## Setup and Configuration\n",
    "\n",
    "Configure paths and load project configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af870911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project Configuration:\n",
      "Region: Lakshadweep\n",
      "Models directory: d:\\Project\\sdb_project\\models\n",
      "Data directory: d:\\Project\\sdb_project\\data\n",
      "Outputs directory: d:\\Project\\sdb_project\\outputs\n",
      "\n",
      "Area of Interest:\n",
      "  Latitude:  10.75Â° to 10.95Â°\n",
      "  Longitude: 72.35Â° to 72.65Â°\n"
     ]
    }
   ],
   "source": [
    "# Load configuration\n",
    "config_path = project_dir / 'config' / 'location_config.json'\n",
    "with open(config_path) as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "# Use parameters if provided\n",
    "if region_name is None:\n",
    "    region_name = config['region_name']\n",
    "\n",
    "# Set up paths\n",
    "region_slug = region_name.lower().replace(' ', '_')\n",
    "if models_dir is None:\n",
    "    models_dir = project_dir / 'models'\n",
    "if output_dir is None:\n",
    "    output_dir = project_dir / 'outputs' / region_slug\n",
    "\n",
    "# Create visualization output directory\n",
    "viz_dir = output_dir / 'visualizations'\n",
    "viz_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"âœ… Final showcase for: {region_name}\")\n",
    "print(f\"ğŸ“ Models directory: {models_dir}\")\n",
    "print(f\"ğŸ“ Output directory: {output_dir}\")\n",
    "print(f\"ğŸ“ Visualizations directory: {viz_dir}\")\n",
    "\n",
    "    \"print(\\\"\\\\nğŸ“ Area of Interest:\\\")\\n\",\n",
    "print(f\"   Latitude:  {config['aoi']['min_lat']}Â° to {config['aoi']['max_lat']}Â°\")\n",
    "print(f\"   Longitude: {config['aoi']['min_lon']}Â° to {config['aoi']['max_lon']}Â°\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b75a5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data and model outputs...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'd:\\\\Project\\\\sdb_project\\\\outputs\\\\Lakshadweep\\\\metrics.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 31\u001b[39m\n\u001b[32m     29\u001b[39m \u001b[38;5;66;03m# Load all data\u001b[39;00m\n\u001b[32m     30\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mLoading data and model outputs...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m metrics, predictions, actual_depths, features, model = \u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mâœ… Data loaded successfully\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 5\u001b[39m, in \u001b[36mload_data\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Load metrics\u001b[39;00m\n\u001b[32m      4\u001b[39m metrics_file = outputs_dir / region_name / \u001b[33m'\u001b[39m\u001b[33mmetrics.json\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmetrics_file\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m      6\u001b[39m     metrics = json.load(f)\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Load model predictions\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Project\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:343\u001b[39m, in \u001b[36m_modified_open\u001b[39m\u001b[34m(file, *args, **kwargs)\u001b[39m\n\u001b[32m    336\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m}:\n\u001b[32m    337\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    338\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mIPython won\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m by default \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    339\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    340\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33myou can use builtins\u001b[39m\u001b[33m'\u001b[39m\u001b[33m open.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    341\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m343\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'd:\\\\Project\\\\sdb_project\\\\outputs\\\\Lakshadweep\\\\metrics.json'"
     ]
    }
   ],
   "source": [
    "# Load model performance metrics\n",
    "metrics_path = output_dir / 'model_metrics.json'\n",
    "comparison_path = output_dir / 'model_performance_comparison.csv'\n",
    "\n",
    "if not metrics_path.exists():\n",
    "    raise FileNotFoundError(f\"Model metrics not found: {metrics_path}\")\n",
    "\n",
    "# Load metrics\n",
    "with open(metrics_path) as f:\n",
    "    model_metrics = json.load(f)\n",
    "\n",
    "print(\"âœ… Loaded model metrics:\")\n",
    "for model_name, metrics in model_metrics.items():\n",
    "    print(f\"   {model_name}: RÂ² = {metrics['r2_score']:.4f}, RMSE = {metrics['rmse']:.4f}\")\n",
    "\n",
    "# Load comparison CSV if available\n",
    "if comparison_path.exists():\n",
    "    metrics_df = pd.read_csv(comparison_path, index_col=0)\n",
    "        \"    print(\\\"âœ… Loaded performance comparison CSV\\\")\\n\",\n",
    "else:\n",
    "    metrics_df = pd.DataFrame(model_metrics).T\n",
    "    \"    print(\\\"âœ… Created metrics dataframe from JSON\\\")\\n\",\n",
    "\n",
    "# Find best model\n",
    "best_model_name = metrics_df['r2_score'].idxmax()\n",
    "best_r2 = metrics_df.loc[best_model_name, 'r2_score']\n",
    "print(f\"\\nğŸ† Best performing model: {best_model_name} (RÂ² = {best_r2:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a95d240",
   "metadata": {},
   "source": [
    "## Model Performance Dashboard\n",
    "\n",
    "Create comprehensive performance comparison visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149deb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive performance dashboard\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# 1. RÂ² Score comparison\n",
    "ax1 = axes[0, 0]\n",
    "models = list(model_metrics.keys())\n",
    "r2_scores = [model_metrics[model]['r2_score'] for model in models]\n",
    "colors = plt.cm.viridis(np.linspace(0, 1, len(models)))\n",
    "\n",
    "bars = ax1.bar(models, r2_scores, color=colors)\n",
    "ax1.set_title('RÂ² Score by Model', fontsize=14, fontweight='bold')\n",
    "ax1.set_ylabel('RÂ² Score')\n",
    "ax1.set_ylim(0, 1)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, score in zip(bars, r2_scores):\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n",
    "             f'{score:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# 2. RMSE comparison\n",
    "ax2 = axes[0, 1]\n",
    "rmse_values = [model_metrics[model]['rmse'] for model in models]\n",
    "bars = ax2.bar(models, rmse_values, color=colors)\n",
    "ax2.set_title('RMSE by Model', fontsize=14, fontweight='bold')\n",
    "ax2.set_ylabel('RMSE (meters)')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Add value labels\n",
    "for bar, rmse in zip(bars, rmse_values):\n",
    "    ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + max(rmse_values)*0.01, \n",
    "             f'{rmse:.2f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# 3. MAE comparison  \n",
    "ax3 = axes[1, 0]\n",
    "mae_values = [model_metrics[model]['mae'] for model in models]\n",
    "bars = ax3.bar(models, mae_values, color=colors)\n",
    "ax3.set_title('Mean Absolute Error by Model', fontsize=14, fontweight='bold')\n",
    "ax3.set_ylabel('MAE (meters)')\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Add value labels\n",
    "for bar, mae in zip(bars, mae_values):\n",
    "    ax3.text(bar.get_x() + bar.get_width()/2, bar.get_height() + max(mae_values)*0.01, \n",
    "             f'{mae:.2f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# 4. All metrics radar chart (simplified as table)\n",
    "ax4 = axes[1, 1] \n",
    "ax4.axis('off')\n",
    "\n",
    "# Create performance table\n",
    "table_data = []\n",
    "for model in models:\n",
    "    metrics = model_metrics[model]\n",
    "    table_data.append([\n",
    "        model,\n",
    "        f\"{metrics['r2_score']:.3f}\",\n",
    "        f\"{metrics['rmse']:.2f}\",\n",
    "        f\"{metrics['mae']:.2f}\",\n",
    "        f\"{metrics['mse']:.2f}\"\n",
    "    ])\n",
    "\n",
    "table = ax4.table(cellText=table_data,\n",
    "                  colLabels=['Model', 'RÂ²', 'RMSE', 'MAE', 'MSE'],\n",
    "                  cellLoc='center',\n",
    "                  loc='center')\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(10)\n",
    "table.scale(1.2, 1.5)\n",
    "\n",
    "# Highlight best model row\n",
    "best_model_idx = models.index(best_model_name) + 1  # +1 for header\n",
    "for j in range(5):\n",
    "    table[(best_model_idx, j)].set_facecolor('#90EE90')  # Light green\n",
    "\n",
    "ax4.set_title('Performance Summary Table\\n(Best model highlighted)', \n",
    "              fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(viz_dir / 'performance_dashboard.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ… Created performance dashboard\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19943fe7",
   "metadata": {},
   "source": [
    "## Feature Importance Analysis\n",
    "\n",
    "Analyze and visualize feature importance from the best performing model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677e32b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best model for feature importance analysis\n",
    "best_model_path = models_dir / f\"{best_model_name}.joblib\"\n",
    "best_model_info_path = models_dir / f\"{best_model_name}_info.json\"\n",
    "\n",
    "if best_model_path.exists() and best_model_info_path.exists():\n",
    "    # Load model and info\n",
    "    best_model = joblib.load(best_model_path)\n",
    "    with open(best_model_info_path) as f:\n",
    "        model_info = json.load(f)\n",
    "    \n",
    "    feature_names = model_info['feature_names']\n",
    "    \n",
    "    # Get feature importance (only for tree-based models)\n",
    "    if hasattr(best_model, 'feature_importances_'):\n",
    "        importances = best_model.feature_importances_\n",
    "        \n",
    "        # Create feature importance visualization\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "        \n",
    "        # 1. Feature importance bar chart\n",
    "        importance_df = pd.DataFrame({\n",
    "            'Feature': feature_names,\n",
    "            'Importance': importances\n",
    "        }).sort_values('Importance', ascending=True)\n",
    "        \n",
    "        colors = plt.cm.plasma(np.linspace(0, 1, len(importance_df)))\n",
    "        bars = ax1.barh(importance_df['Feature'], importance_df['Importance'], color=colors)\n",
    "        ax1.set_title(f'Feature Importance - {best_model_name}', fontsize=14, fontweight='bold')\n",
    "        ax1.set_xlabel('Importance Score')\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Add value labels\n",
    "        for i, (bar, importance) in enumerate(zip(bars, importance_df['Importance'])):\n",
    "            ax1.text(importance + max(importance_df['Importance'])*0.01, bar.get_y() + bar.get_height()/2,\n",
    "                     f'{importance:.3f}', va='center', ha='left', fontweight='bold')\n",
    "        \n",
    "        # 2. Feature importance pie chart (top 6 features)\n",
    "        top_features = importance_df.tail(6)\n",
    "        colors_pie = plt.cm.Set3(np.linspace(0, 1, len(top_features)))\n",
    "        \n",
    "        wedges, texts, autotexts = ax2.pie(top_features['Importance'], \n",
    "                                           labels=top_features['Feature'],\n",
    "                                           autopct='%1.1f%%',\n",
    "                                           colors=colors_pie,\n",
    "                                           startangle=90)\n",
    "        ax2.set_title('Top 6 Most Important Features', fontsize=14, fontweight='bold')\n",
    "        \n",
    "        # Improve text readability\n",
    "        for autotext in autotexts:\n",
    "            autotext.set_color('white')\n",
    "            autotext.set_fontweight('bold')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(viz_dir / 'feature_importance.png', dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        \n",
    "        print(f\"âœ… Created feature importance analysis for {best_model_name}\")\n",
    "        print(f\"ğŸ“Š Most important feature: {importance_df.iloc[-1]['Feature']} ({importance_df.iloc[-1]['Importance']:.3f})\")\n",
    "        \n",
    "    else:\n",
    "        print(f\"âš ï¸  Feature importance not available for {best_model_name} (not a tree-based model)\")\n",
    "        \n",
    "else:\n",
    "    print(f\"âš ï¸  Best model files not found: {best_model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe9f762",
   "metadata": {},
   "source": [
    "## Training Data Analysis\n",
    "\n",
    "Analyze the synthetic depth data distribution and model training characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b839a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data to analyze synthetic depth distribution\n",
    "training_data_dir = project_dir / 'data' / 'sentinel' / region_slug / 'processed' / 'training_data'\n",
    "feature_metadata_path = training_data_dir / 'feature_metadata.json'\n",
    "\n",
    "if feature_metadata_path.exists():\n",
    "    with open(feature_metadata_path) as f:\n",
    "        training_metadata = json.load(f)\n",
    "    \n",
    "    # Create training data analysis visualization\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # 1. Dataset size info\n",
    "    ax1 = axes[0, 0]\n",
    "    ax1.axis('off')\n",
    "    \n",
    "    info_text = f\"\"\"\n",
    "    Dataset Summary\n",
    "    \n",
    "    Region: {training_metadata['region_name']}\n",
    "    \n",
    "    Samples: {training_metadata['n_samples']:,}\n",
    "    Features: {training_metadata['n_features']}\n",
    "    Water Pixels: {training_metadata['water_pixel_count']:,}\n",
    "    \n",
    "    Feature Names:\n",
    "    {chr(10).join(['â€¢ ' + name for name in training_metadata['feature_names']])}\n",
    "    \"\"\"\n",
    "    \n",
    "    ax1.text(0.05, 0.95, info_text, transform=ax1.transAxes, fontsize=12,\n",
    "             verticalalignment='top', fontfamily='monospace',\n",
    "             bbox=dict(boxstyle='round,pad=0.5', facecolor='lightblue', alpha=0.8))\n",
    "    \n",
    "    # 2. Depth statistics\n",
    "    depth_stats = training_metadata['depth_stats']\n",
    "    ax2 = axes[0, 1]\n",
    "    \n",
    "    stats_labels = ['Min', 'Mean', 'Max', 'Std Dev']\n",
    "    stats_values = [depth_stats['min'], depth_stats['mean'], \n",
    "                   depth_stats['max'], depth_stats['std']]\n",
    "    \n",
    "    colors = ['#ff6b6b', '#4ecdc4', '#45b7d1', '#96ceb4']\n",
    "    bars = ax2.bar(stats_labels, stats_values, color=colors)\n",
    "    ax2.set_title('Synthetic Depth Statistics', fontsize=14, fontweight='bold')\n",
    "    ax2.set_ylabel('Depth (meters)')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add value labels\n",
    "    for bar, value in zip(bars, stats_values):\n",
    "        ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + max(stats_values)*0.01,\n",
    "                 f'{value:.1f}m', ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    # 3. Model count and types\n",
    "    ax3 = axes[1, 0]\n",
    "    model_names = list(model_metrics.keys())\n",
    "    model_counts = [1] * len(model_names)  # Each model trained once\n",
    "    \n",
    "    colors = plt.cm.tab10(np.linspace(0, 1, len(model_names)))\n",
    "    bars = ax3.bar(model_names, model_counts, color=colors)\n",
    "    ax3.set_title('Models Trained', fontsize=14, fontweight='bold')\n",
    "    ax3.set_ylabel('Count')\n",
    "    ax3.set_ylim(0, 2)\n",
    "    \n",
    "    # Add checkmarks\n",
    "    for bar in bars:\n",
    "        ax3.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.05,\n",
    "                 'âœ“', ha='center', va='bottom', fontsize=20, color='green', fontweight='bold')\n",
    "    \n",
    "    # 4. Performance summary\n",
    "    ax4 = axes[1, 1]\n",
    "    \n",
    "    performance_summary = f\"\"\"\n",
    "    ğŸ† Best Model Performance\n",
    "    \n",
    "    Model: {best_model_name}\n",
    "    RÂ² Score: {best_r2:.4f}\n",
    "    RMSE: {model_metrics[best_model_name]['rmse']:.2f} meters\n",
    "    MAE: {model_metrics[best_model_name]['mae']:.2f} meters\n",
    "    \n",
    "    ğŸ’¡ Training Notes:\n",
    "    â€¢ Synthetic depth data generated\n",
    "    â€¢ Features scaled using StandardScaler  \n",
    "    â€¢ 80/20 train-test split\n",
    "    â€¢ Multiple ML algorithms tested\n",
    "    \"\"\"\n",
    "    \n",
    "    ax4.text(0.05, 0.95, performance_summary, transform=ax4.transAxes, fontsize=11,\n",
    "             verticalalignment='top', fontfamily='monospace',\n",
    "             bbox=dict(boxstyle='round,pad=0.5', facecolor='lightgreen', alpha=0.8))\n",
    "    ax4.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(viz_dir / 'training_analysis.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"âœ… Created training data analysis\")\n",
    "    \n",
    "else:\n",
    "    print(\"âš ï¸  Training metadata not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56706cf",
   "metadata": {},
   "source": [
    "## Final Summary Report\n",
    "\n",
    "Generate a comprehensive summary of the entire bathymetry analysis pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee2ab43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate final summary report\n",
    "print(\"=\" * 80)\n",
    "print(f\"ğŸŒŠ SATELLITE-DERIVED BATHYMETRY ANALYSIS COMPLETE ğŸŒŠ\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"\\nğŸ“ REGION: {region_name}\")\n",
    "print(f\"ğŸ“… Analysis Date: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "print(f\"\\nğŸ“Š DATASET SUMMARY:\")\n",
    "if 'training_metadata' in locals():\n",
    "    print(f\"   â€¢ Samples analyzed: {training_metadata['n_samples']:,}\")\n",
    "    print(f\"   â€¢ Features extracted: {training_metadata['n_features']}\")\n",
    "    print(f\"   â€¢ Water pixels: {training_metadata['water_pixel_count']:,}\")\n",
    "    print(f\"   â€¢ Depth range: {training_metadata['depth_stats']['min']:.1f} - {training_metadata['depth_stats']['max']:.1f} meters\")\n",
    "\n",
    "print(f\"\\nğŸ¤– MODELS TRAINED:\")\n",
    "for i, (model_name, metrics) in enumerate(model_metrics.items(), 1):\n",
    "    status = \"ğŸ†\" if model_name == best_model_name else \"âœ…\"\n",
    "    print(f\"   {i}. {status} {model_name}\")\n",
    "    print(f\"      RÂ² = {metrics['r2_score']:.4f}, RMSE = {metrics['rmse']:.2f}m, MAE = {metrics['mae']:.2f}m\")\n",
    "\n",
    "print(f\"\\nğŸ¯ PIPELINE STAGES COMPLETED:\")\n",
    "pipeline_stages = [\n",
    "    \"01. Sentinel-2 Data Download âœ…\",\n",
    "    \"02. Data Preprocessing âœ…\", \n",
    "    \"03. Feature Generation âœ…\",\n",
    "    \"04. Model Training âœ…\",\n",
    "    \"05. Performance Evaluation âœ…\",\n",
    "    \"06. Visualization Generation âœ…\"\n",
    "]\n",
    "\n",
    "for stage in pipeline_stages:\n",
    "    print(f\"   {stage}\")\n",
    "\n",
    "print(f\"\\nğŸ“ OUTPUT FILES GENERATED:\")\n",
    "output_files = [\n",
    "    f\"Performance Dashboard: {viz_dir / 'performance_dashboard.png'}\",\n",
    "    f\"Feature Importance: {viz_dir / 'feature_importance.png'}\",\n",
    "    f\"Training Analysis: {viz_dir / 'training_analysis.png'}\",\n",
    "    f\"Model Metrics: {output_dir / 'model_metrics.json'}\",\n",
    "    f\"Performance Comparison: {output_dir / 'model_performance_comparison.csv'}\"\n",
    "]\n",
    "\n",
    "for file_desc in output_files:\n",
    "    print(f\"   ğŸ“„ {file_desc}\")\n",
    "\n",
    "print(f\"\\nğŸ’¾ TRAINED MODELS SAVED:\")\n",
    "for model_name in model_metrics.keys():\n",
    "    model_path = models_dir / f\"{model_name}.joblib\"\n",
    "    if model_path.exists():\n",
    "        print(f\"   ğŸ¤– {model_name}: {model_path}\")\n",
    "\n",
    "print(f\"\\nğŸ‰ SUCCESS! Bathymetry analysis pipeline completed successfully.\")\n",
    "print(f\"ğŸ† Best performing model: {best_model_name} (RÂ² = {best_r2:.4f})\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Save summary report\n",
    "summary_report = {\n",
    "    'analysis_date': pd.Timestamp.now().isoformat(),\n",
    "    'region': region_name,\n",
    "    'best_model': best_model_name,\n",
    "    'best_r2': float(best_r2),\n",
    "    'models_trained': list(model_metrics.keys()),\n",
    "    'total_models': len(model_metrics),\n",
    "    'output_directory': str(output_dir),\n",
    "    'models_directory': str(models_dir),\n",
    "    'visualizations_directory': str(viz_dir)\n",
    "}\n",
    "\n",
    "if 'training_metadata' in locals():\n",
    "    summary_report.update({\n",
    "        'dataset_size': training_metadata['n_samples'],\n",
    "        'n_features': training_metadata['n_features'],\n",
    "        'water_pixels': training_metadata['water_pixel_count'],\n",
    "        'depth_range': training_metadata['depth_stats']\n",
    "    })\n",
    "\n",
    "summary_path = output_dir / 'pipeline_summary.json'\n",
    "with open(summary_path, 'w') as f:\n",
    "    json.dump(summary_report, f, indent=2)\n",
    "\n",
    "print(f\"\\nğŸ“‹ Summary report saved: {summary_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f983770f",
   "metadata": {},
   "source": [
    "## Advanced 3D/4D Visualizations Integration\n",
    "\n",
    "Execute advanced visualization scripts from the visualisations directory to generate comprehensive 3D plots, heatmaps, and interactive analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007345dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced Visualizations Integration\n",
    "print(\"ğŸ¨ Loading Advanced Visualization Extensions...\")\n",
    "\n",
    "try:\n",
    "    # Import our advanced visualization system\n",
    "    from src.visualize import run_advanced_visualizations\n",
    "    \n",
    "    # Create final showcase directory\n",
    "    final_showcase_dir = output_dir / 'final_showcase'\n",
    "    final_showcase_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Run advanced visualizations\n",
    "    print(\"ğŸš€ Executing advanced visualization scripts...\")\n",
    "    advanced_files = run_advanced_visualizations(final_showcase_dir)\n",
    "    \n",
    "    if advanced_files:\n",
    "        print(f\"\\nğŸ‰ Advanced Visualization Files Generated:\")\n",
    "        for file_path in advanced_files:\n",
    "            print(f\"  âœ… {file_path}\")\n",
    "        \n",
    "        # Update summary report with advanced visualizations\n",
    "        if 'summary_report' in locals():\n",
    "            summary_report['advanced_visualizations'] = advanced_files\n",
    "            summary_report['total_visualizations'] = len(advanced_files)\n",
    "            \n",
    "            # Re-save updated summary\n",
    "            with open(summary_path, 'w') as f:\n",
    "                json.dump(summary_report, f, indent=2)\n",
    "            \n",
    "            print(f\"\\nğŸ“‹ Updated summary report with {len(advanced_files)} advanced visualizations\")\n",
    "        \n",
    "        # Show file sizes and types\n",
    "        print(f\"\\nğŸ“Š Advanced Visualization Summary:\")\n",
    "        html_files = [f for f in advanced_files if f.endswith('.html')]\n",
    "        png_files = [f for f in advanced_files if f.endswith('.png')]\n",
    "        \n",
    "        if html_files:\n",
    "            print(f\"  ğŸŒ Interactive HTML plots: {len(html_files)}\")\n",
    "            for html_file in html_files[:3]:  # Show first 3\n",
    "                print(f\"    â€¢ {html_file}\")\n",
    "            if len(html_files) > 3:\n",
    "                print(f\"    â€¢ ... and {len(html_files) - 3} more\")\n",
    "                \n",
    "        if png_files:\n",
    "            print(f\"  ğŸ–¼ï¸  Static PNG plots: {len(png_files)}\")\n",
    "            for png_file in png_files[:3]:  # Show first 3\n",
    "                print(f\"    â€¢ {png_file}\")\n",
    "            if len(png_files) > 3:\n",
    "                print(f\"    â€¢ ... and {len(png_files) - 3} more\")\n",
    "        \n",
    "    else:\n",
    "        print(\"â„¹ï¸  No advanced visualization files were generated\")\n",
    "        print(\"    This is normal if:\")\n",
    "        print(\"    â€¢ No visualization scripts are present in visualisations/\")\n",
    "        print(\"    â€¢ Scripts encountered errors during execution\")\n",
    "        print(\"    â€¢ Data files are missing or in different locations\")\n",
    "        \n",
    "except ImportError as e:\n",
    "    print(f\"âš ï¸  Could not load advanced visualization system: {e}\")\n",
    "    print(\"â„¹ï¸  This is normal if the visualization module is not properly set up\")\n",
    "    print(\"    The basic visualizations above were still created successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error in advanced visualizations: {e}\")\n",
    "    print(\"âš ï¸  Advanced visualizations failed, but basic pipeline completed successfully\")\n",
    "    import traceback\n",
    "    print(\"\\nError details:\")\n",
    "    traceback.print_exc()\n",
    "\n",
    "print(\"âœ… Advanced visualization integration complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e635981b",
   "metadata": {},
   "source": [
    "## Final Output Directory Structure\n",
    "\n",
    "Display the complete structure of generated files for easy access and reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2671fecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display final output directory structure\n",
    "print(\"ğŸ“ GENERATED OUTPUT STRUCTURE:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "def print_directory_tree(directory, prefix=\"\", max_depth=3, current_depth=0):\n",
    "    \"\"\"Print directory tree structure\"\"\"\n",
    "    if current_depth > max_depth:\n",
    "        return\n",
    "        \n",
    "    try:\n",
    "        items = sorted(directory.iterdir())\n",
    "        dirs = [item for item in items if item.is_dir()]\n",
    "        files = [item for item in items if item.is_file()]\n",
    "        \n",
    "        # Print directories first\n",
    "        for i, item in enumerate(dirs):\n",
    "            is_last_dir = (i == len(dirs) - 1) and len(files) == 0\n",
    "            print(f\"{prefix}{'â””â”€â”€ ' if is_last_dir else 'â”œâ”€â”€ '}{item.name}/\")\n",
    "            \n",
    "            extension = \"    \" if is_last_dir else \"â”‚   \"\n",
    "            print_directory_tree(item, prefix + extension, max_depth, current_depth + 1)\n",
    "        \n",
    "        # Print files\n",
    "        for i, item in enumerate(files):\n",
    "            is_last = i == len(files) - 1\n",
    "            size_mb = item.stat().st_size / (1024 * 1024)\n",
    "            size_str = f\" ({size_mb:.1f}MB)\" if size_mb > 0.1 else f\" ({item.stat().st_size}B)\"\n",
    "            \n",
    "            print(f\"{prefix}{'â””â”€â”€ ' if is_last else 'â”œâ”€â”€ '}{item.name}{size_str}\")\n",
    "            \n",
    "    except PermissionError:\n",
    "        print(f\"{prefix}[Permission Denied]\")\n",
    "\n",
    "# Start from output directory\n",
    "print(f\"{output_dir.name}/\")\n",
    "print_directory_tree(output_dir)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"ğŸ‰ BATHYMETRY ANALYSIS PIPELINE COMPLETE!\")\n",
    "print(f\"ğŸ“Š Check {output_dir} for all results\")\n",
    "print(f\"ğŸŒ Interactive plots in {output_dir}/final_showcase/\")\n",
    "print(f\"ğŸ“ˆ Performance dashboards in {viz_dir}/\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af774b6a",
   "metadata": {},
   "source": [
    "## Advanced 3D/4D Visualizations Integration\n",
    "\n",
    "Execute advanced visualization scripts from the visualisations directory to generate comprehensive 3D plots, heatmaps, and interactive analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61317b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced Visualizations Integration\n",
    "print(\"ğŸ¨ Loading Advanced Visualization Extensions...\")\n",
    "\n",
    "try:\n",
    "    # Import our advanced visualization system\n",
    "    from src.visualize import run_advanced_visualizations\n",
    "    \n",
    "    # Create final showcase directory\n",
    "    final_showcase_dir = output_dir / 'final_showcase'\n",
    "    final_showcase_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Run advanced visualizations\n",
    "    print(f\"ğŸš€ Executing advanced visualization scripts...\")\n",
    "    advanced_files = run_advanced_visualizations(final_showcase_dir)\n",
    "    \n",
    "    if advanced_files:\n",
    "        print(f\"\\nğŸ‰ Advanced Visualization Files Generated:\")\n",
    "        for file_path in advanced_files:\n",
    "            print(f\"  âœ… {file_path}\")\n",
    "        \n",
    "        # Update summary report with advanced visualizations\n",
    "        if 'summary_report' in locals():\n",
    "            summary_report['advanced_visualizations'] = advanced_files\n",
    "            summary_report['total_visualizations'] = len(advanced_files)\n",
    "            \n",
    "            # Re-save updated summary\n",
    "            with open(summary_path, 'w') as f:\n",
    "                json.dump(summary_report, f, indent=2)\n",
    "            \n",
    "            print(f\"\\nğŸ“‹ Updated summary report with {len(advanced_files)} advanced visualizations\")\n",
    "        \n",
    "        # Show file sizes and types\n",
    "        print(f\"\\nğŸ“Š Advanced Visualization Summary:\")\n",
    "        html_files = [f for f in advanced_files if f.endswith('.html')]\n",
    "        png_files = [f for f in advanced_files if f.endswith('.png')]\n",
    "        \n",
    "        if html_files:\n",
    "            print(f\"  ğŸŒ Interactive HTML plots: {len(html_files)}\")\n",
    "            for html_file in html_files[:3]:  # Show first 3\n",
    "                print(f\"    â€¢ {html_file}\")\n",
    "            if len(html_files) > 3:\n",
    "                print(f\"    â€¢ ... and {len(html_files) - 3} more\")\n",
    "                \n",
    "        if png_files:\n",
    "            print(f\"  ğŸ–¼ï¸  Static PNG plots: {len(png_files)}\")\n",
    "            for png_file in png_files[:3]:  # Show first 3\n",
    "                print(f\"    â€¢ {png_file}\")\n",
    "            if len(png_files) > 3:\n",
    "                print(f\"    â€¢ ... and {len(png_files) - 3} more\")\n",
    "        \n",
    "    else:\n",
    "        print(\"â„¹ï¸  No advanced visualization files were generated\")\n",
    "        print(\"    This is normal if:\")\n",
    "        print(\"    â€¢ No visualization scripts are present in visualisations/\")\n",
    "        print(\"    â€¢ Scripts encountered errors during execution\")\n",
    "        print(\"    â€¢ Data files are missing or in different locations\")\n",
    "        \n",
    "except ImportError as e:\n",
    "    print(f\"âš ï¸  Could not load advanced visualization system: {e}\")\n",
    "    print(\"â„¹ï¸  This is normal if the visualization module is not properly set up\")\n",
    "    print(\"    The basic visualizations above were still created successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error in advanced visualizations: {e}\")\n",
    "    print(\"âš ï¸  Advanced visualizations failed, but basic pipeline completed successfully\")\n",
    "    import traceback\n",
    "    print(\"\\nError details:\")\n",
    "    traceback.print_exc()\n",
    "\n",
    "print(\"âœ… Advanced visualization integration complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81febacc",
   "metadata": {},
   "source": [
    "## Final Output Directory Structure\n",
    "\n",
    "Display the complete structure of generated files for easy access and reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d88d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display final output directory structure\n",
    "print(\"ğŸ“ GENERATED OUTPUT STRUCTURE:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "def print_directory_tree(directory, prefix=\"\", max_depth=3, current_depth=0):\n",
    "    \"\"\"Print directory tree structure\"\"\"\n",
    "    if current_depth > max_depth:\n",
    "        return\n",
    "        \n",
    "    try:\n",
    "        items = sorted(directory.iterdir())\n",
    "        dirs = [item for item in items if item.is_dir()]\n",
    "        files = [item for item in items if item.is_file()]\n",
    "        \n",
    "        # Print directories first\n",
    "        for i, item in enumerate(dirs):\n",
    "            is_last_dir = (i == len(dirs) - 1) and len(files) == 0\n",
    "            print(f\"{prefix}{'â””â”€â”€ ' if is_last_dir else 'â”œâ”€â”€ '}{item.name}/\")\n",
    "            \n",
    "            extension = \"    \" if is_last_dir else \"â”‚   \"\n",
    "            print_directory_tree(item, prefix + extension, max_depth, current_depth + 1)\n",
    "        \n",
    "        # Print files\n",
    "        for i, item in enumerate(files):\n",
    "            is_last = i == len(files) - 1\n",
    "            size_mb = item.stat().st_size / (1024 * 1024)\n",
    "            size_str = f\" ({size_mb:.1f}MB)\" if size_mb > 0.1 else f\" ({item.stat().st_size}B)\"\n",
    "            \n",
    "            print(f\"{prefix}{'â””â”€â”€ ' if is_last else 'â”œâ”€â”€ '}{item.name}{size_str}\")\n",
    "            \n",
    "    except PermissionError:\n",
    "        print(f\"{prefix}[Permission Denied]\")\n",
    "\n",
    "# Start from output directory\n",
    "print(f\"{output_dir.name}/\")\n",
    "print_directory_tree(output_dir)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"ğŸ‰ BATHYMETRY ANALYSIS PIPELINE COMPLETE!\")\n",
    "print(f\"ğŸ“Š Check {output_dir} for all results\")\n",
    "print(f\"ğŸŒ Interactive plots in {output_dir}/final_showcase/\")\n",
    "print(f\"ğŸ“ˆ Performance dashboards in {viz_dir}/\")\n",
    "print(\"=\" * 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
