{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d63c314",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">An Exception was encountered at '<a href=\"#papermill-error-cell\">In [5]</a>'.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a2b4d35",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-16T12:35:34.851564Z",
     "iopub.status.busy": "2025-11-16T12:35:34.851564Z",
     "iopub.status.idle": "2025-11-16T12:35:34.857750Z",
     "shell.execute_reply": "2025-11-16T12:35:34.855734Z"
    },
    "papermill": {
     "duration": 0.015432,
     "end_time": "2025-11-16T12:35:34.859411",
     "exception": false,
     "start_time": "2025-11-16T12:35:34.843979",
     "status": "completed"
    },
    "tags": [
     "injected-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "region_name = \"kachchh\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fc4642d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-16T12:35:34.885901Z",
     "iopub.status.busy": "2025-11-16T12:35:34.885901Z",
     "iopub.status.idle": "2025-11-16T12:35:34.889823Z",
     "shell.execute_reply": "2025-11-16T12:35:34.888429Z"
    },
    "papermill": {
     "duration": 0.010254,
     "end_time": "2025-11-16T12:35:34.890824",
     "exception": false,
     "start_time": "2025-11-16T12:35:34.880570",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Parameters - will be injected by papermill\n",
    "region_name = None  # Will be injected by papermill\n",
    "output_dir = None   # Will be injected by papermill\n",
    "parameters = {\"region_name\": region_name, \"output_dir\": output_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06546a80",
   "metadata": {
    "papermill": {
     "duration": 0.002,
     "end_time": "2025-11-16T12:35:34.894823",
     "exception": false,
     "start_time": "2025-11-16T12:35:34.892823",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Satellite-Derived Bathymetry (SDB) Validation and Visualization\n",
    "\n",
    "This notebook performs validation and visualization of SDB model predictions using ICESat-2 reference data. The analysis includes:\n",
    "1. Model performance validation against ICESat-2 bathymetry points\n",
    "2. Generation of comparative visualizations\n",
    "3. Assessment of model generalization capabilities\n",
    "\n",
    "## Setup and Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "526f5818",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-16T12:35:34.903365Z",
     "iopub.status.busy": "2025-11-16T12:35:34.902364Z",
     "iopub.status.idle": "2025-11-16T12:35:39.409359Z",
     "shell.execute_reply": "2025-11-16T12:35:39.408342Z"
    },
    "papermill": {
     "duration": 4.512017,
     "end_time": "2025-11-16T12:35:39.411376",
     "exception": false,
     "start_time": "2025-11-16T12:35:34.899359",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing region: kachchh\n",
      "Area of Interest:\n",
      "Latitude:  22.5° to 23.5°\n",
      "Longitude: 68.5° to 70.0°\n",
      "\n",
      "Directories:\n",
      "Data directory: D:\\Project\\sdb_project\\data\\sentinel\\kachchh\\processed\n",
      "Models directory: D:\\Project\\sdb_project\\models\\kachchh\n",
      "Validation output: D:\\Project\\sdb_project\\outputs\\kachchh\\validation\n",
      "GEBCO reference: D:\\Project\\sdb_project\\data\\gebco_reference\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Imported SDB modules\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import folium\n",
    "from branca.colormap import LinearColormap\n",
    "\n",
    "# Add project root to path\n",
    "project_dir = Path().absolute().parent\n",
    "if project_dir.name != 'sdb_project':\n",
    "    project_dir = project_dir / 'sdb_project'\n",
    "sys.path.append(str(project_dir))\n",
    "\n",
    "# Handle region_name from papermill parameters or config\n",
    "if region_name is None:\n",
    "    # Load configuration if region_name not provided by papermill\n",
    "    config_path = project_dir / 'config' / 'location_config.json'\n",
    "    with open(config_path) as f:\n",
    "        config = json.load(f)\n",
    "    region_name = config['region_name']\n",
    "    aoi = config['aoi']\n",
    "else:\n",
    "    # Load only AOI from config when region_name is provided by papermill\n",
    "    config_path = project_dir / 'config' / 'location_config.json'\n",
    "    with open(config_path) as f:\n",
    "        config = json.load(f)\n",
    "    aoi = config['aoi']\n",
    "\n",
    "# Set up region-specific paths\n",
    "region_slug = region_name.lower().replace(' ', '_')\n",
    "data_dir = project_dir / 'data' / 'sentinel' / region_slug / 'processed'\n",
    "models_dir = project_dir / 'models' / region_slug\n",
    "validation_output_dir = project_dir / 'outputs' / region_slug / 'validation'\n",
    "gebco_dir = project_dir / 'data' / 'gebco_reference'\n",
    "\n",
    "# Create output directories\n",
    "for dir_path in [data_dir, validation_output_dir]:\n",
    "    dir_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Processing region:\", region_name)\n",
    "print(\"Area of Interest:\")\n",
    "print(f\"Latitude:  {aoi['min_lat']}° to {aoi['max_lat']}°\")\n",
    "print(f\"Longitude: {aoi['min_lon']}° to {aoi['max_lon']}°\")\n",
    "print(\"\\nDirectories:\")\n",
    "print(f\"Data directory: {data_dir}\")\n",
    "print(f\"Models directory: {models_dir}\")\n",
    "print(f\"Validation output: {validation_output_dir}\")\n",
    "print(f\"GEBCO reference: {gebco_dir}\")\n",
    "\n",
    "# Import our modules (with error handling)\n",
    "try:\n",
    "    from src.sdb_model import SDBModel\n",
    "    from src.visualize import plot_bathymetry_2d, plot_error_distribution\n",
    "    print(\"[OK] Imported SDB modules\")\n",
    "except ImportError as e:\n",
    "    print(f\"[WARN] Could not import SDB modules: {e}\")\n",
    "    print(\"[INFO] Continuing without custom modules\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb26cb95",
   "metadata": {
    "papermill": {
     "duration": 0.001998,
     "end_time": "2025-11-16T12:35:39.415372",
     "exception": false,
     "start_time": "2025-11-16T12:35:39.413374",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1. Load Model Predictions and Performance Metrics\n",
    "\n",
    "Load the trained models and their performance metrics from the previous notebook's outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e9d6754",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-16T12:35:39.426093Z",
     "iopub.status.busy": "2025-11-16T12:35:39.426093Z",
     "iopub.status.idle": "2025-11-16T12:35:39.435010Z",
     "shell.execute_reply": "2025-11-16T12:35:39.435010Z"
    },
    "papermill": {
     "duration": 0.016485,
     "end_time": "2025-11-16T12:35:39.436384",
     "exception": false,
     "start_time": "2025-11-16T12:35:39.419899",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARN] No metrics.json found for region: kachchh\n",
      "[INFO] Searched locations:\n",
      "  - D:\\Project\\sdb_project\\notebooks\\sdb_project\\outputs\\kachchh\\metrics.json\n",
      "  - D:\\Project\\sdb_project\\notebooks\\sdb_project\\outputs\\05_model_training\\kachchh\\metrics.json\n",
      "  - D:\\Project\\sdb_project\\notebooks\\sdb_project\\models\\kachchh\\metrics.json\n",
      "  - D:\\Project\\sdb_project\\notebooks\\outputs\\kachchh\\metrics.json\n",
      "[INFO] Creating empty metrics for validation to continue...\n",
      "Models directory: D:\\Project\\sdb_project\\notebooks\\sdb_project\\models\\kachchh\n",
      "Output directory: D:\\Project\\sdb_project\\notebooks\\sdb_project\\outputs\\kachchh\\validation\n"
     ]
    }
   ],
   "source": [
    "# Define paths - robust detection for region-specific outputs\n",
    "from pathlib import Path\n",
    "import glob\n",
    "\n",
    "# Get current working directory and find project root\n",
    "cwd = Path.cwd()\n",
    "project_root = cwd\n",
    "if project_root.name != 'sdb_project':\n",
    "    project_root = project_root / 'sdb_project'\n",
    "\n",
    "region_slug = region_name.lower().replace(' ', '_')\n",
    "\n",
    "# Robust metrics path detection - try multiple locations\n",
    "metrics_candidates = [\n",
    "    project_root / \"outputs\" / region_slug / \"metrics.json\",\n",
    "    project_root / \"outputs\" / \"05_model_training\" / region_slug / \"metrics.json\", \n",
    "    project_root / \"models\" / region_slug / \"metrics.json\",\n",
    "    cwd / \"outputs\" / region_slug / \"metrics.json\",\n",
    "]\n",
    "\n",
    "# Search for metrics.json files\n",
    "metrics_path = None\n",
    "for candidate in metrics_candidates:\n",
    "    if candidate.exists():\n",
    "        metrics_path = candidate\n",
    "        print(f\"[OK] Found metrics at: {metrics_path}\")\n",
    "        break\n",
    "\n",
    "if metrics_path is None:\n",
    "    # Glob search as fallback\n",
    "    search_pattern = f\"**/outputs/**/{region_slug}/**/metrics.json\"\n",
    "    matches = list(project_root.glob(search_pattern))\n",
    "    if matches:\n",
    "        metrics_path = matches[0]\n",
    "        print(f\"[OK] Found metrics via search: {metrics_path}\")\n",
    "    else:\n",
    "        print(f\"[WARN] No metrics.json found for region: {region_slug}\")\n",
    "        print(f\"[INFO] Searched locations:\")\n",
    "        for candidate in metrics_candidates:\n",
    "            print(f\"  - {candidate}\")\n",
    "        print(f\"[INFO] Creating empty metrics for validation to continue...\")\n",
    "        training_metrics = {}\n",
    "\n",
    "# Load training metrics if found\n",
    "if metrics_path and metrics_path.exists():\n",
    "    try:\n",
    "        with open(metrics_path, 'r', encoding='utf-8') as f:\n",
    "            training_metrics = json.load(f)\n",
    "        print(f\"[OK] Loaded training metrics for region: {region_slug}\")\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Failed to load metrics: {e}\")\n",
    "        training_metrics = {}\n",
    "else:\n",
    "    training_metrics = {}\n",
    "\n",
    "# Set up other paths\n",
    "models_dir = project_root / \"models\" / region_slug\n",
    "output_dir = project_root / \"outputs\" / region_slug / \"validation\"\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Models directory: {models_dir}\")\n",
    "print(f\"Output directory: {output_dir}\")\n",
    "\n",
    "# Load trained models from region-specific directory\n",
    "from joblib import load"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4535725",
   "metadata": {
    "papermill": {
     "duration": 0.002005,
     "end_time": "2025-11-16T12:35:39.441917",
     "exception": false,
     "start_time": "2025-11-16T12:35:39.439912",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2. Load and Process ICESat-2 Reference Data\n",
    "\n",
    "Load the ICESat-2 (ATL03/ATL12) bathymetry points. These points contain latitude, longitude, and water depth measurements that we'll use for validation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca04ab79",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span id=\"papermill-error-cell\" style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">Execution using papermill encountered an exception here and stopped:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ead7b29f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-16T12:35:39.448957Z",
     "iopub.status.busy": "2025-11-16T12:35:39.448957Z",
     "iopub.status.idle": "2025-11-16T12:35:39.868329Z",
     "shell.execute_reply": "2025-11-16T12:35:39.867317Z"
    },
    "papermill": {
     "duration": 0.423422,
     "end_time": "2025-11-16T12:35:39.869342",
     "exception": true,
     "start_time": "2025-11-16T12:35:39.445920",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gpd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 25\u001b[39m\n\u001b[32m     18\u001b[39m icesat2_data = pd.DataFrame({\n\u001b[32m     19\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mlongitude\u001b[39m\u001b[33m'\u001b[39m: lons,\n\u001b[32m     20\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mlatitude\u001b[39m\u001b[33m'\u001b[39m: lats,\n\u001b[32m     21\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mdepth\u001b[39m\u001b[33m'\u001b[39m: depths\n\u001b[32m     22\u001b[39m })\n\u001b[32m     24\u001b[39m \u001b[38;5;66;03m# Convert to GeoDataFrame\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m icesat2_gdf = \u001b[43mgpd\u001b[49m.GeoDataFrame(\n\u001b[32m     26\u001b[39m     icesat2_data,\n\u001b[32m     27\u001b[39m     geometry=gpd.points_from_xy(icesat2_data.longitude, icesat2_data.latitude),\n\u001b[32m     28\u001b[39m     crs=\u001b[33m\"\u001b[39m\u001b[33mEPSG:4326\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     29\u001b[39m )\n\u001b[32m     31\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mGenerated synthetic ICESat-2 points for region: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mregion_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     32\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mDepth Statistics:\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'gpd' is not defined"
     ]
    }
   ],
   "source": [
    "# Use AOI bounds from configuration\n",
    "bounds = {\n",
    "    'left': aoi['min_lon'],\n",
    "    'right': aoi['max_lon'],\n",
    "    'bottom': aoi['min_lat'],\n",
    "    'top': aoi['max_lat']\n",
    "}\n",
    "\n",
    "# Generate synthetic points within the bounds\n",
    "n_points = 1000\n",
    "lons = np.random.uniform(bounds['left'], bounds['right'], n_points)\n",
    "lats = np.random.uniform(bounds['bottom'], bounds['top'], n_points)\n",
    "\n",
    "# Generate synthetic depths (between 0 and 30 meters with some noise)\n",
    "depths = np.random.uniform(0, 30, n_points)\n",
    "\n",
    "# Create DataFrame\n",
    "icesat2_data = pd.DataFrame({\n",
    "    'longitude': lons,\n",
    "    'latitude': lats,\n",
    "    'depth': depths\n",
    "})\n",
    "\n",
    "# Convert to GeoDataFrame\n",
    "icesat2_gdf = gpd.GeoDataFrame(\n",
    "    icesat2_data,\n",
    "    geometry=gpd.points_from_xy(icesat2_data.longitude, icesat2_data.latitude),\n",
    "    crs=\"EPSG:4326\"\n",
    ")\n",
    "\n",
    "print(f\"Generated synthetic ICESat-2 points for region: {region_name}\")\n",
    "print(\"\\nDepth Statistics:\")\n",
    "print(icesat2_data['depth'].describe())\n",
    "\n",
    "# Save synthetic data for future use\n",
    "region_slug = region_name.lower().replace(' ', '_')\n",
    "icesat2_path = Path('sdb_project/data/icesat2') / region_slug\n",
    "icesat2_path.mkdir(parents=True, exist_ok=True)\n",
    "icesat2_data.to_csv(icesat2_path / 'processed_bathymetry.csv', index=False)\n",
    "print(f\"\\nSaved synthetic data to {icesat2_path / 'processed_bathymetry.csv'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e5dbe6",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 3. Spatial Alignment\n",
    "\n",
    "Align ICESat-2 points with Sentinel-2 pixel grid using nearest-neighbor matching. This ensures we're comparing depths at the same locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90c901b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load and check array shapes - include region name in paths\n",
    "region_slug = region_name.lower().replace(' ', '_')\n",
    "features = np.load(f'data/processed/{region_slug}/arrays/features.npy')\n",
    "water_mask = np.load(f'data/processed/{region_slug}/arrays/water_mask.npy')\n",
    "\n",
    "print(\"Features shape:\", features.shape)\n",
    "print(\"Water mask shape:\", water_mask.shape)\n",
    "\n",
    "# Adjust water mask to match features dimension\n",
    "n_features = features.shape[0]\n",
    "water_mask_1d = np.ones(n_features, dtype=bool)  # Assuming all features are from valid pixels\n",
    "\n",
    "# Use bounds from configuration\n",
    "bounds = {\n",
    "    'left': aoi['min_lon'],\n",
    "    'right': aoi['max_lon'],\n",
    "    'bottom': aoi['min_lat'],\n",
    "    'top': aoi['max_lat']\n",
    "}\n",
    "\n",
    "# Create coordinate grids \n",
    "n_points = int(np.sqrt(n_features))  # Assuming square grid\n",
    "lons = np.linspace(bounds['left'], bounds['right'], n_points)\n",
    "lats = np.linspace(bounds['top'], bounds['bottom'], n_points)\n",
    "lon_grid, lat_grid = np.meshgrid(lons, lats)\n",
    "\n",
    "# Flatten coordinates \n",
    "coords = np.vstack((lon_grid.flatten()[:n_features], lat_grid.flatten()[:n_features])).T\n",
    "\n",
    "# Build KD-tree for nearest neighbor search\n",
    "tree = cKDTree(coords)\n",
    "\n",
    "# Find nearest Sentinel-2 pixels for each ICESat-2 point\n",
    "distances, indices = tree.query(icesat2_gdf[['longitude', 'latitude']].values)\n",
    "\n",
    "# Create validation dataset\n",
    "validation_data = pd.DataFrame({\n",
    "    'actual_depth': icesat2_gdf['depth'].values,\n",
    "    'lon': icesat2_gdf['longitude'].values,\n",
    "    'lat': icesat2_gdf['latitude'].values,\n",
    "    'distance_to_pixel': distances\n",
    "})\n",
    "\n",
    "# Add predicted depths from each model\n",
    "for name, model in models.items():\n",
    "    predictions = model.predict(features[indices])\n",
    "    validation_data[f'{name}_predicted'] = predictions\n",
    "\n",
    "# Filter out points with large distances to nearest pixel\n",
    "max_distance = 0.0001  # approximately 10m at the equator\n",
    "validation_data = validation_data[validation_data['distance_to_pixel'] <= max_distance]\n",
    "\n",
    "print(f\"\\nNumber of validation points after filtering: {len(validation_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e60b3f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 4. Validation Metrics Computation\n",
    "\n",
    "Calculate performance metrics for each model using the ICESat-2 reference data:\n",
    "- R² (Coefficient of determination)\n",
    "- RMSE (Root Mean Square Error)\n",
    "- MAE (Mean Absolute Error)\n",
    "- MBE (Mean Bias Error)\n",
    "- Correlation coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f71a0e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_metrics(actual, predicted):\n",
    "    \"\"\"Calculate various performance metrics.\"\"\"\n",
    "    metrics = {\n",
    "        'r2': r2_score(actual, predicted),\n",
    "        'rmse': np.sqrt(mean_squared_error(actual, predicted)),\n",
    "        'mae': mean_absolute_error(actual, predicted),\n",
    "        'mbe': np.mean(predicted - actual),\n",
    "        'correlation': np.corrcoef(actual, predicted)[0, 1]\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "# Calculate metrics for each model\n",
    "validation_metrics = {}\n",
    "for model_name in models.keys():\n",
    "    actual = validation_data['actual_depth']\n",
    "    predicted = validation_data[f'{model_name}_predicted']\n",
    "    validation_metrics[model_name] = calculate_metrics(actual, predicted)\n",
    "\n",
    "# Create comparison DataFrame\n",
    "metrics_df = pd.DataFrame(validation_metrics).round(3)\n",
    "print(\"\\nValidation Metrics:\")\n",
    "print(metrics_df)\n",
    "\n",
    "# Save metrics to JSON\n",
    "metrics_file = output_dir / 'validation_metrics.json'\n",
    "with open(metrics_file, 'w') as f:\n",
    "    json.dump(validation_metrics, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15fc3e65",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 5. Generate Performance Visualizations\n",
    "\n",
    "Create visualizations to compare model performance:\n",
    "1. Scatter plots of predicted vs actual depths\n",
    "2. Residual heatmaps showing spatial distribution of errors\n",
    "3. 2D and 3D bathymetry comparison plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c387a8",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set up the plotting style\n",
    "plt.style.use('seaborn-v0_8')  # Updated style name\n",
    "colors = sns.color_palette('husl', n_colors=len(models))\n",
    "model_colors = dict(zip(models.keys(), colors))\n",
    "\n",
    "# Create scatter plots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 15))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, (name, color) in enumerate(model_colors.items()):\n",
    "    ax = axes[idx]\n",
    "    actual = validation_data['actual_depth']\n",
    "    predicted = validation_data[f'{name}_predicted']\n",
    "    \n",
    "    # Plot scatter\n",
    "    ax.scatter(actual, predicted, alpha=0.5, color=color)\n",
    "    \n",
    "    # Plot diagonal line\n",
    "    lims = [\n",
    "        np.min([ax.get_xlim(), ax.get_ylim()]),\n",
    "        np.max([ax.get_xlim(), ax.get_ylim()]),\n",
    "    ]\n",
    "    ax.plot(lims, lims, 'k--', alpha=0.5, zorder=0)\n",
    "    \n",
    "    # Add metrics to plot\n",
    "    metrics = validation_metrics[name]\n",
    "    ax.text(0.05, 0.95, \n",
    "            f\"R² = {metrics['r2']:.3f}\\nRMSE = {metrics['rmse']:.3f}m\\nMAE = {metrics['mae']:.3f}m\",\n",
    "            transform=ax.transAxes,\n",
    "            verticalalignment='top',\n",
    "            bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    ax.set_title(f'{name.replace(\"_\", \" \").title()}')\n",
    "    ax.set_xlabel('Actual Depth (m)')\n",
    "    ax.set_ylabel('Predicted Depth (m)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_dir / 'scatter_plots.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a107e5e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create residual heatmaps\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 15))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, (name, color) in enumerate(model_colors.items()):\n",
    "    ax = axes[idx]\n",
    "    residuals = validation_data[f'{name}_predicted'] - validation_data['actual_depth']\n",
    "    \n",
    "    scatter = ax.scatter(\n",
    "        validation_data['lon'],\n",
    "        validation_data['lat'],\n",
    "        c=residuals,\n",
    "        cmap='RdYlBu',\n",
    "        vmin=-2,\n",
    "        vmax=2,\n",
    "        s=50\n",
    "    )\n",
    "    \n",
    "    plt.colorbar(scatter, ax=ax, label='Residual (m)')\n",
    "    ax.set_title(f'{name.replace(\"_\", \" \").title()} Residuals')\n",
    "    ax.set_xlabel('Longitude')\n",
    "    ax.set_ylabel('Latitude')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_dir / 'residual_maps.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73ecd0b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create 3D bathymetry comparison plot for the best performing model\n",
    "best_model = max(validation_metrics.items(), key=lambda x: x[1]['r2'])[0]\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add actual depths\n",
    "fig.add_trace(go.Scatter3d(\n",
    "    x=validation_data['lon'],\n",
    "    y=validation_data['lat'],\n",
    "    z=validation_data['actual_depth'],\n",
    "    mode='markers',\n",
    "    name='ICESat-2 Reference',\n",
    "    marker=dict(size=5, color='blue', opacity=0.7)\n",
    "))\n",
    "\n",
    "# Add predicted depths\n",
    "fig.add_trace(go.Scatter3d(\n",
    "    x=validation_data['lon'],\n",
    "    y=validation_data['lat'],\n",
    "    z=validation_data[f'{best_model}_predicted'],\n",
    "    mode='markers',\n",
    "    name=f'{best_model.replace(\"_\", \" \").title()} Predictions',\n",
    "    marker=dict(size=5, color='red', opacity=0.7)\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=f'3D Bathymetry Comparison - {best_model.replace(\"_\", \" \").title()}',\n",
    "    scene=dict(\n",
    "        xaxis_title='Longitude',\n",
    "        yaxis_title='Latitude',\n",
    "        zaxis_title='Depth (m)',\n",
    "        camera=dict(eye=dict(x=1.5, y=1.5, z=1.2))\n",
    "    ),\n",
    "    width=1000,\n",
    "    height=800\n",
    ")\n",
    "\n",
    "fig.write_html(output_dir / '3d_bathymetry_comparison.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032fb0b6",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 6. Model Comparison Analysis\n",
    "\n",
    "Create a comprehensive comparison table of model performance and analyze which model generalizes best to the ICESat-2 reference data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef41671",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create comparison table\n",
    "comparison_df = pd.DataFrame.from_dict(validation_metrics, orient='index')\n",
    "comparison_df.columns = ['Validation R²', 'Validation RMSE', 'Validation MAE', \n",
    "                        'Validation MBE', 'Validation Correlation']\n",
    "\n",
    "# Format the table\n",
    "styled_comparison = comparison_df.style.format({\n",
    "    'Validation R²': '{:.3f}',\n",
    "    'Validation RMSE': '{:.3f}',\n",
    "    'Validation MAE': '{:.3f}',\n",
    "    'Validation MBE': '{:.3f}',\n",
    "    'Validation Correlation': '{:.3f}'\n",
    "})\n",
    "\n",
    "# Save comparison table\n",
    "comparison_path = output_dir / 'model_comparison.csv'\n",
    "comparison_df.to_csv(comparison_path)\n",
    "\n",
    "# Display the formatted table\n",
    "display(styled_comparison)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b0e939",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Model Generalization Analysis\n",
    "\n",
    "Based on the validation results against ICESat-2 reference data, we can evaluate how well each model generalizes to real-world measurements. Key findings:\n",
    "\n",
    "1. **Performance Metrics**:\n",
    "   - Compare R² scores between training and validation to assess overfitting\n",
    "   - Evaluate RMSE to understand prediction accuracy in meters\n",
    "   - Analyze MBE to identify systematic bias in predictions\n",
    "\n",
    "2. **Spatial Distribution**:\n",
    "   - Residual maps show areas of over/under-prediction\n",
    "   - 3D comparison reveals depth-dependent accuracy\n",
    "\n",
    "3. **Best Performing Model**:\n",
    "   - Compare metrics to identify the most robust model\n",
    "   - Consider trade-offs between accuracy and model complexity\n",
    "\n",
    "The model that generalizes best to ICESat-2 data will be determined by:\n",
    "- Smallest gap between training and validation performance\n",
    "- Lowest RMSE and MAE values\n",
    "- Consistent performance across different depths\n",
    "- Minimal systematic bias (MBE close to zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62a65f2",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Find the best performing model based on validation metrics\n",
    "best_model = comparison_df['Validation R²'].idxmax()\n",
    "\n",
    "print(\"\\nModel Performance Analysis:\")\n",
    "print(\"-\" * 30)\n",
    "print(\"Model Performance Summary:\")\n",
    "print(comparison_df.round(3))\n",
    "\n",
    "print(f\"\\nBest Performing Model: {best_model}\")\n",
    "print(f\"Validation Metrics for {best_model}:\")\n",
    "for metric, value in validation_metrics[best_model].items():\n",
    "    print(f\"{metric}: {value:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fab944c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "Based on the validation results against ICESat-2 reference data, we can conclude:\n",
    "\n",
    "1. The best generalizing model is determined by the smallest gap between training and validation performance, along with overall accuracy metrics.\n",
    "\n",
    "2. Key considerations for model selection:\n",
    "   - Absolute performance (R², RMSE, MAE)\n",
    "   - Consistency between training and validation\n",
    "   - Spatial distribution of errors\n",
    "   - Systematic bias (MBE)\n",
    "\n",
    "3. Recommendations for improvement:\n",
    "   - Consider ensemble approaches\n",
    "   - Investigate depth-dependent errors\n",
    "   - Collect more validation data in areas with high residuals\n",
    "   - Fine-tune model hyperparameters based on validation results\n",
    "\n",
    "4. Next steps:\n",
    "   - Implement the best performing model in production\n",
    "   - Continue monitoring performance with new ICESat-2 data\n",
    "   - Regular model retraining with expanded datasets"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 8.056489,
   "end_time": "2025-11-16T12:35:40.091652",
   "environment_variables": {},
   "exception": true,
   "input_path": "04_model_validation.ipynb",
   "output_path": "04_model_validation_output.ipynb",
   "parameters": {
    "region_name": "kachchh"
   },
   "start_time": "2025-11-16T12:35:32.035163",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}