{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "584ee89c",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "source": [
    "# Feature Generation for Bathymetry Modeling\n",
    "\n",
    "This notebook generates additional features from the preprocessed Sentinel-2 data for bathymetry modeling.\n",
    "\n",
    "Steps:\n",
    "1. Load preprocessed features and water mask\n",
    "2. Generate additional spectral features\n",
    "3. Create training dataset\n",
    "4. Save features for model training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3a17e5",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e92c41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "region_name = \"Lakshadweep\"\n",
    "features_path = None\n",
    "output_dir = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1009ca5c",
   "metadata": {},
   "source": [
    "## Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e182b3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using data from: test_mangalore\\data\\sentinel\\mangalore\n",
      "Output directories created at: data\\processed\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Add project root to path\n",
    "project_dir = Path().absolute().parent\n",
    "if project_dir.name != 'sdb_project':\n",
    "    project_dir = project_dir / 'sdb_project'\n",
    "sys.path.append(str(project_dir))\n",
    "\n",
    "# Load configurations\n",
    "config_path = project_dir / 'config' / 'location_config.json'\n",
    "with open(config_path) as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "# Load notebook configuration with SAFE file information\n",
    "notebook_config_path = project_dir / 'config' / 'notebook_config.json'\n",
    "notebook_config = {}\n",
    "if notebook_config_path.exists():\n",
    "    with open(notebook_config_path) as f:\n",
    "        notebook_config = json.load(f)\n",
    "    logger.info(f\"Loaded notebook config for region: {notebook_config.get('region', 'Unknown')}\")\n",
    "    logger.info(f\"Using SAFE file: {notebook_config.get('safe_file_name', 'Not set')}\")\n",
    "\n",
    "# Load band extraction configuration\n",
    "band_config_path = project_dir / 'config' / 'band_extraction_config.json'\n",
    "band_config = {}\n",
    "if band_config_path.exists():\n",
    "    with open(band_config_path) as f:\n",
    "        band_config = json.load(f)\n",
    "    logger.info(f\"Loaded band config with {len(band_config.get('bands', []))} bands\")\n",
    "\n",
    "# Use parameters if provided, otherwise use configuration\n",
    "if region_name is None:\n",
    "    region_name = notebook_config.get('region', config.get('region_name', 'unknown'))\n",
    "\n",
    "# Set up paths using the new configuration\n",
    "safe_file_path = notebook_config.get('safe_file_path', '')\n",
    "data_root = notebook_config.get('data_root', f'data/sentinel/{region_name}')\n",
    "output_root = notebook_config.get('output_root', f'outputs/{region_name}')\n",
    "\n",
    "logger.info(f\"Working with region: {region_name}\")\n",
    "logger.info(f\"Data root: {data_root}\")\n",
    "logger.info(f\"Output root: {output_root}\")\n",
    "if safe_file_path:\n",
    "    logger.info(f\"SAFE file: {Path(safe_file_path).name}\")\n",
    "\n",
    "# Set up paths\n",
    "region_slug = region_name.lower().replace(' ', '_')\n",
    "processed_data_dir = project_dir / 'data' / 'sentinel' / region_slug / 'processed'\n",
    "if output_dir is None:\n",
    "    output_dir = project_dir / 'outputs' / region_slug\n",
    "\n",
    "Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"‚úÖ Feature generation for: {region_name}\")\n",
    "print(f\"üìÅ Data directory: {processed_data_dir}\")\n",
    "print(f\"üìÅ Output directory: {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6347ffb",
   "metadata": {},
   "source": [
    "## Load Preprocessed Data\n",
    "\n",
    "Load the features and water mask from the preprocessing step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac7c09b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting B02...\n",
      "Found B02 at test_mangalore\\data\\sentinel\\mangalore\\43PGQ_B02.jp2\n",
      "Extracting B03...\n",
      "Found B03 at test_mangalore\\data\\sentinel\\mangalore\\43PGQ_B03.jp2\n",
      "Extracting B03...\n",
      "Found B03 at test_mangalore\\data\\sentinel\\mangalore\\43PGQ_B03.jp2\n",
      "Extracting B04...\n",
      "Found B04 at test_mangalore\\data\\sentinel\\mangalore\\43PGQ_B04.jp2\n",
      "Extracting B04...\n",
      "Found B04 at test_mangalore\\data\\sentinel\\mangalore\\43PGQ_B04.jp2\n",
      "Extracting B08...\n",
      "Found B08 at test_mangalore\\data\\sentinel\\mangalore\\43PGQ_B08.jp2\n",
      "Extracting B08...\n",
      "Found B08 at test_mangalore\\data\\sentinel\\mangalore\\43PGQ_B08.jp2\n",
      "Warning: QA60 band not found or could not be extracted: Could not find QA60 in test_mangalore\\data\\sentinel\\mangalore using patterns: ['QA60.jp2', 'mangalore_QA60.jp2', '*_QA60.jp2']\n",
      "Band extraction complete!\n",
      "Warning: QA60 band not found or could not be extracted: Could not find QA60 in test_mangalore\\data\\sentinel\\mangalore using patterns: ['QA60.jp2', 'mangalore_QA60.jp2', '*_QA60.jp2']\n",
      "Band extraction complete!\n"
     ]
    }
   ],
   "source": [
    "# Load preprocessed data\n",
    "if features_path is None:\n",
    "    features_path = processed_data_dir / 'features.npy'\n",
    "\n",
    "water_mask_path = processed_data_dir / 'water_mask.npy'\n",
    "metadata_path = processed_data_dir / 'processing_metadata.json'\n",
    "\n",
    "# Check if files exist\n",
    "if not features_path.exists():\n",
    "    raise FileNotFoundError(f\"Features file not found: {features_path}\")\n",
    "if not water_mask_path.exists():\n",
    "    raise FileNotFoundError(f\"Water mask not found: {water_mask_path}\")\n",
    "\n",
    "# Load data\n",
    "features = np.load(features_path)\n",
    "water_mask = np.load(water_mask_path)\n",
    "\n",
    "print(f\"‚úÖ Loaded features with shape: {features.shape}\")\n",
    "print(f\"‚úÖ Loaded water mask with shape: {water_mask.shape}\")\n",
    "\n",
    "# Load metadata if available\n",
    "feature_names = ['B02', 'B03', 'B04', 'B08']  # Default names\n",
    "if metadata_path.exists():\n",
    "    with open(metadata_path) as f:\n",
    "        metadata = json.load(f)\n",
    "    if 'feature_names' in metadata['processing_info']:\n",
    "        feature_names = metadata['processing_info']['feature_names']\n",
    "\n",
    "print(f\"üìä Feature names: {feature_names}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c94300",
   "metadata": {},
   "source": [
    "## Generate Additional Features\n",
    "\n",
    "Create additional spectral features that are useful for bathymetry estimation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618bb0e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QA60 band not available, skipping cloud masking...\n",
      "Cloud masking applied to all bands\n",
      "Cloud masking applied to all bands\n"
     ]
    }
   ],
   "source": [
    "# Extract water pixels only (flatten to 1D arrays)\n",
    "water_pixels = features[water_mask]\n",
    "print(f\"üìä Water pixels for analysis: {len(water_pixels)}\")\n",
    "\n",
    "if len(water_pixels) == 0:\n",
    "    raise ValueError(\"No water pixels found! Check water mask.\")\n",
    "\n",
    "# Remove NaN values\n",
    "valid_mask = ~np.isnan(water_pixels).any(axis=1)\n",
    "water_pixels = water_pixels[valid_mask]\n",
    "print(f\"üìä Valid water pixels: {len(water_pixels)}\")\n",
    "\n",
    "# Generate additional features from the spectral bands\n",
    "def generate_spectral_features(pixels):\n",
    "    \"\"\"Generate additional spectral features for bathymetry\"\"\"\n",
    "    if pixels.shape[1] < 4:\n",
    "        raise ValueError(f\"Expected at least 4 bands, got {pixels.shape[1]}\")\n",
    "    \n",
    "    # Assuming order: B02, B03, B04, B08, [indices...]\n",
    "    b02, b03, b04, b08 = pixels[:, 0], pixels[:, 1], pixels[:, 2], pixels[:, 3]\n",
    "    \n",
    "    additional_features = []\n",
    "    additional_names = []\n",
    "    \n",
    "    # Band ratios (useful for water depth)\n",
    "    ratios = {\n",
    "        'B02_B04_ratio': b02 / (b04 + 1e-8),\n",
    "        'B03_B04_ratio': b03 / (b04 + 1e-8), \n",
    "        'B02_B03_ratio': b02 / (b03 + 1e-8),\n",
    "        'B08_B04_ratio': b08 / (b04 + 1e-8)\n",
    "    }\n",
    "    \n",
    "    # Log-transformed bands (better for depth correlation)\n",
    "    log_bands = {\n",
    "        'log_B02': np.log(b02 + 1e-6),\n",
    "        'log_B03': np.log(b03 + 1e-6),\n",
    "        'log_B04': np.log(b04 + 1e-6)\n",
    "    }\n",
    "    \n",
    "    # Combine all additional features\n",
    "    all_additional = {**ratios, **log_bands}\n",
    "    \n",
    "    for name, values in all_additional.items():\n",
    "        if not np.any(np.isnan(values)) and not np.any(np.isinf(values)):\n",
    "            additional_features.append(values.reshape(-1, 1))\n",
    "            additional_names.append(name)\n",
    "    \n",
    "    if additional_features:\n",
    "        return np.hstack(additional_features), additional_names\n",
    "    else:\n",
    "        return np.array([]).reshape(len(pixels), 0), []\n",
    "\n",
    "# Generate additional features\n",
    "additional_features, additional_names = generate_spectral_features(water_pixels)\n",
    "print(f\"‚úÖ Generated {len(additional_names)} additional features: {additional_names}\")\n",
    "\n",
    "# Combine original and additional features\n",
    "if additional_features.size > 0:\n",
    "    all_features = np.hstack([water_pixels, additional_features])\n",
    "    all_feature_names = feature_names + additional_names\n",
    "else:\n",
    "    all_features = water_pixels\n",
    "    all_feature_names = feature_names\n",
    "\n",
    "print(f\"üìä Total features: {all_features.shape[1]}\")\n",
    "print(f\"üìä Feature names: {all_feature_names}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974a0d7b",
   "metadata": {},
   "source": [
    "## Generate Synthetic Depth Data\n",
    "\n",
    "Since we don't have real bathymetry data, generate synthetic depth values for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f751363e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying atmospheric correction...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:preprocess:Successfully corrected 4 bands\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Atmospheric correction complete!\n"
     ]
    }
   ],
   "source": [
    "# Generate synthetic depth data for training\n",
    "# This is a placeholder - in reality you would use ICESat-2, sonar, or other depth measurements\n",
    "np.random.seed(42)  # Reproducible results\n",
    "\n",
    "def generate_synthetic_depths(features):\n",
    "    \"\"\"Generate realistic synthetic depth values based on spectral features\"\"\"\n",
    "    \n",
    "    # Use blue band (B02) as primary depth indicator\n",
    "    blue_band = features[:, 0]  # First feature should be B02\n",
    "    \n",
    "    # Normalize blue band\n",
    "    blue_norm = (blue_band - np.nanmin(blue_band)) / (np.nanmax(blue_band) - np.nanmin(blue_band))\n",
    "    \n",
    "    # Create depth relationship: deeper water = lower reflectance in blue\n",
    "    # Invert and scale to reasonable depth range (0-30 meters)\n",
    "    base_depth = (1 - blue_norm) * 25.0 + 2.0  # 2-27 meter range\n",
    "    \n",
    "    # Add some noise and complexity\n",
    "    # Use green/blue ratio for additional variation\n",
    "    if features.shape[1] > 1:\n",
    "        green_blue_ratio = features[:, 1] / (features[:, 0] + 1e-8)\n",
    "        depth_variation = green_blue_ratio * 5.0  # Up to 5m variation\n",
    "        base_depth += depth_variation\n",
    "    \n",
    "    # Add random noise (measurement uncertainty)\n",
    "    noise = np.random.normal(0, 1.5, len(base_depth))\n",
    "    synthetic_depth = base_depth + noise\n",
    "    \n",
    "    # Ensure positive depths\n",
    "    synthetic_depth = np.clip(synthetic_depth, 0.5, 50.0)\n",
    "    \n",
    "    return synthetic_depth\n",
    "\n",
    "# Generate synthetic depths\n",
    "depths = generate_synthetic_depths(all_features)\n",
    "print(f\"‚úÖ Generated {len(depths)} synthetic depth measurements\")\n",
    "print(f\"üìä Depth range: {np.min(depths):.1f} - {np.max(depths):.1f} meters\")\n",
    "print(f\"üìä Mean depth: {np.mean(depths):.1f} ¬± {np.std(depths):.1f} meters\")\n",
    "\n",
    "# Visualize depth distribution\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(depths, bins=30, alpha=0.7, edgecolor='black')\n",
    "plt.xlabel('Depth (meters)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Synthetic Depth Distribution')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(all_features[:, 0], depths, alpha=0.5, s=1)\n",
    "plt.xlabel('Blue Band Reflectance (B02)')\n",
    "plt.ylabel('Depth (meters)')\n",
    "plt.title('Depth vs Blue Band')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(Path(output_dir) / 'synthetic_depth_analysis.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a38efa6",
   "metadata": {},
   "source": [
    "## Prepare Training Dataset\n",
    "\n",
    "Scale features and prepare the final dataset for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d93be2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating water indices...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:preprocess:Calculated indices: ['NDWI', 'MNDWI', 'SR', 'BR_ratio']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating water mask...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:preprocess:Created water mask with 25437 water pixels\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Water indices and mask calculation complete!\n",
      "Available indices: ['NDWI', 'MNDWI', 'SR', 'BR_ratio']\n",
      "Number of water pixels: 25437\n"
     ]
    }
   ],
   "source": [
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(all_features)\n",
    "\n",
    "print(f\"‚úÖ Scaled features to zero mean and unit variance\")\n",
    "print(f\"üìä Feature means: {np.mean(scaled_features, axis=0).round(3)}\")\n",
    "print(f\"üìä Feature stds: {np.std(scaled_features, axis=0).round(3)}\")\n",
    "\n",
    "# Save training data\n",
    "training_data_dir = processed_data_dir / 'training_data'\n",
    "training_data_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Save features, depths, and scaler\n",
    "np.save(training_data_dir / 'features.npy', scaled_features)\n",
    "np.save(training_data_dir / 'depths.npy', depths)\n",
    "\n",
    "# Save scaler\n",
    "import joblib\n",
    "scaler_path = training_data_dir / 'feature_scaler.joblib'\n",
    "joblib.dump(scaler, scaler_path)\n",
    "\n",
    "print(f\"‚úÖ Saved training features: {training_data_dir / 'features.npy'}\")\n",
    "print(f\"‚úÖ Saved depths: {training_data_dir / 'depths.npy'}\")\n",
    "print(f\"‚úÖ Saved scaler: {scaler_path}\")\n",
    "\n",
    "# Save feature metadata\n",
    "feature_metadata = {\n",
    "    'region_name': region_name,\n",
    "    'n_samples': len(scaled_features),\n",
    "    'n_features': len(all_feature_names),\n",
    "    'feature_names': all_feature_names,\n",
    "    'depth_stats': {\n",
    "        'min': float(np.min(depths)),\n",
    "        'max': float(np.max(depths)), \n",
    "        'mean': float(np.mean(depths)),\n",
    "        'std': float(np.std(depths))\n",
    "    },\n",
    "    'water_pixel_count': len(water_pixels),\n",
    "    'training_data_paths': {\n",
    "        'features': str(training_data_dir / 'features.npy'),\n",
    "        'depths': str(training_data_dir / 'depths.npy'),\n",
    "        'scaler': str(scaler_path)\n",
    "    }\n",
    "}\n",
    "\n",
    "metadata_path = training_data_dir / 'feature_metadata.json'\n",
    "with open(metadata_path, 'w') as f:\n",
    "    json.dump(feature_metadata, f, indent=2)\n",
    "\n",
    "print(f\"‚úÖ Saved metadata: {metadata_path}\")\n",
    "print(f\"\\nüéØ Feature generation complete! Ready for model training.\")\n",
    "print(f\"üìä Dataset summary:\")\n",
    "print(f\"   - Samples: {feature_metadata['n_samples']:,}\")\n",
    "print(f\"   - Features: {feature_metadata['n_features']} ({', '.join(all_feature_names[:5])}...)\")\n",
    "print(f\"   - Depth range: {feature_metadata['depth_stats']['min']:.1f} - {feature_metadata['depth_stats']['max']:.1f}m\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
